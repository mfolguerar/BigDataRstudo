---
title: "T칠cnicas de aprendizaje no supervisado. Dendogramas y K-medias"
author: "Lu칤s Filipe Milhomem da Silva Paix칚o y Marcos Folguera Rivera"
date: "2023-05-04"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: true
    smooth_scroll: true
    theme: journal
    highlight: kate
    df_print: paged
    code_folding: show
---

```{r}
library(pgmm)
data(wine)
attach(wine)
```
# 1. El objetivo es utilizar K-medias con 洧 = 3 para dividir los datos en 3 grupos, sin utilizar la variable Type. Una vez obtenido el conjunto, comparar los grupos obtenidos con las distintas subvariedades definidas por Type
##a) Utiliza el procedimiento de K-medias para particionar los datos en 洧 = 3 grupos utilizando 칰nicamente las 27 variables num칠ricas
```{r}
library(pgmm)
data(wine)
attach(wine)
library(stats)
wine_num <- wine[,2:28] 
k <- 3
set.seed(1) 
km_res <- kmeans(wine_num, k) #Aplicamos K-medias

#La variaci칩n total se encuentra en:
km_res$tot.withinss
#Los grupos asignados los podemos recuperar con:
clusters=km_res$cluster
table(clusters, Type)
#En esta matriz de pueden apreciar los 3 grupos  , y asignamos el grupo al valor mas alto (type=3 para el grupo=1 ,type=1 para el grupo=2 y type=2 para el grupo=3) el proceso de selecion lo haremos en el siguiente apartado.

```
#b) Construye la matriz de confusi칩n. Teniendo en cuenta que los subgrupos pueden renombrarse, 쯖u치l es el porcentaje de acierto de este modelo?
```{r}

table(clusters, Type)
#asignar el grupo 1 a la subvariedad 3, grupo 2 a la subvariedad 1 ,grupo 3 a la subvariedad 2
sub_grupo <- c(3, 1, 2) 
sub_grupo_clusters <- sub_grupo[clusters] 

# Construimos la matriz de confusi칩n
mc <- table(sub_grupo_clusters, Type)
mc

# Calculamos el porcentaje de acierto
correctos <- sum(diag(mc))
accuracy <- correctos / nrow(wine_num) * 100
accuracy
```
#c) Normaliza las variables predictoras y repite el proceso de K-medias para 洧 = 3
```{r}
wine_norm <- scale(wine_num) 
set.seed(1) 
km_res_norm <- kmeans(wine_norm, k) 
clusters_norm <- km_res_norm$cluster 
table_clusters_type_norm <- table(clusters_norm, Type)
sub_grupo_norm <- apply(table_clusters_type_norm, 1, which.max)
sub_grupo_clusters_norm <-sub_grupo_norm[clusters_norm]
mc_norm <- table(sub_grupo_clusters_norm, Type)
mc_norm
accuracy_norm <- sum(diag(mc_norm)) / sum(mc_norm)
accuracy_norm
#el modelo con normalizaci칩n de variables tiene una precisi칩n del 97.75% lo que mejora claramente el anterior

```
#d) Compara el porcentaje de acierto del algoritmo tras normalizar las variables predictoras. 쯄erece la pena normalizar las variables?
```{r}
mejora_porcentaje = ((0.9775281 - 0.741573) / 0.741573) * 100
mejora_porcentaje
#el modelo con normalizaci칩n de variables tiene una mejora del 31.82% en comparaci칩n con el modelo sin normalizaci칩n de variables. 
#Por tanto claramente merece la pena normalizar 
```
#e) Explora la posible existencia de m치s subvariedades a partir de los resultados obtenidos con Kmedias utilizando K=1,2,3,...,10. 쮺u치ntos subgrupos parece haber en este conjunto de datos?
```{r}
library(pgmm)
data(wine)
wine_num <- wine[,2:14] 
set.seed(1)
inertia <- vector()
Wtot<-c()
for(k in 1 :10){
  Wtot[k]<-kmeans(x,centers=k,nstart = 20)$tot.withinss
  
}
plot(x=c(1:10),y=Wtot)
#Para cada valor de K, podemos calcular la suma total de cuadrados dentro de los grupos =inercia
#Obtenemos un gr치fico que muestra c칩mo la inercia disminuye a medida que aumentamos el n칰mero de grupos
#Como los datos representan diferentes tipos de vino y a partir de K=3 la disminuci칩n es mucho m치s lenta ,esto sugiere que hay al menos 3 subgrupos en los datos que coindice con los 3 tipos de vinos del conjunto de datos
```


# 2. Aplica el procedimiento de agrupamiento jer치rquico sobre el conjunto de datos wine.

El dendrograma es una herramienta visual que nos permite ver la estructura jer치rquica de los datos y c칩mo se agrupan en diferentes niveles.

## a) Realiza un dendograma con enlace 칰nico haciendo uso de los 27 predictores del conjunto wine. Representa el dendograma y muestra los 3 grupos seleccionados.

```{r}
wine_dist <- dist(wine[,1:27])
```

```{r}
wine_dend_unico <- hclust(wine_dist, method = "single")
plot(wine_dend_unico, main="Enlace 칰nico"); rect.hclust(wine_dend_unico,k=3)

```

## b) Realiza un dendograma con enlace medio haciendo uso de los 27 predictores del conjunto wine. Representa el dendograma y muestra los 3 grupos seleccionados.

```{r}
wine_dend_medio <- hclust(wine_dist, method = "average")
plot(wine_dend_medio, main="Enlace medio"); rect.hclust(wine_dend_medio,k=3)

```

## c) Realiza un dendograma con enlace completo haciendo uso de los 27 predictores del conjunto wine. Representa el dendograma y muestra los 3 grupos seleccionados.

```{r}
wine_dend_completo <- hclust(wine_dist, method = "complete")
plot(wine_dend_completo, main="Enlace completo");rect.hclust(wine_dend_completo,k=3)

```

## d) Haciendo uso de la matriz de confusi칩n, determina el porcentaje de acierto de cada uno de estos dendogramas a la hora de clasificar las 3 variedades de vino comparando sus resultados con los valores de Type. (De nuevo, ten en cuenta que los subconjuntos que ha creado el dendograma no tienen porqu칠 tomar el mismo valor que toma en Type).

Definimos la funci칩n `metricas` que nos permitir치 obtener valores de nuestro inter칠s como el error global.

```{r}
metricas<-function(mc){ #mc es una matriz de confusi칩n
  esp<-mc[1,1]/sum(mc[,1])
  sen<-mc[2,2]/sum(mc[,2])
  ag<-sum(diag(mc))/sum(mc)
  eg<-1-ag
  m<-cbind(esp,sen,ag,eg)
  colnames(m)=c("Especificidad","Sensibilidad","Exactitud","Error global")
  rownames(m)="valor"
  m
}
```

### El error para diferentes valores de k

Con la funci칩n `cutree` utilizamos para cortar un dendograma en un n칰mero de determinados grupos. Aqu칤 buscamos generar diferentes resultados para distintos agrupamientos con el objetivo de conseguir el mejor. Al cortar el dendrograma en diferentes valores de `k`, podemos obtener diferentes agrupamientos de los datos y evaluar la calidad de los clusters resultantes. Comparar los resultados de varios dendrogramas generados a partir de diferentes valores de k es importante para determinar el n칰mero 칩ptimo de clusters para un conjunto de datos dado y evaluar la calidad de los clusters resultantes.

```{r warning=FALSE}
resultados_unico <- c()
resultados_medio <- c()
resultados_completo <- c()
for(i in 2:10) {
  wine_groups_unico <- cutree(wine_dend_unico, k = i)
  resultados_unico[i] <- metricas(table(Type,wine_groups_unico))[4]
  
  wine_groups_medio <- cutree(wine_dend_medio, k = i)
  resultados_medio[i] <- metricas(table(Type,wine_groups_medio))[4]
  
  wine_groups_completo <- cutree(wine_dend_completo, k=i)
  resultados_completo[i] <- metricas(table(Type,wine_groups_completo))[4]
}

library(ggplot2)

df <- data.frame(i = 1:10, 
                 resultados_unico = resultados_unico, 
                 resultados_medio = resultados_medio, 
                 resultados_completo = resultados_completo)

ggplot(df, aes(x = i)) +
  geom_line(aes(y = resultados_unico, color = "Resultados Unico")) +
  geom_line(aes(y = resultados_medio, color = "Resultados Medio")) +
  geom_line(aes(y = resultados_completo, color = "Resultados Completo")) +
  labs(title = "El error en distintos agrupamientos", 
       x = "N칰mero de grupos", 
       y = "Error global") +
  scale_color_manual(values = c("Resultados Unico" = "red", 
                                "Resultados Medio" = "blue", 
                                "Resultados Completo" = "green")) +
  scale_x_continuous(breaks = seq(1, 10, 1))

```

Al observar el gr치fico, podemos ver mejor como se comporta los dendrogramas con distintos valores de grupo. Con estos valores podemos sacar lo mejor de cada dendograma y su matriz de confusi칩n.

### Matriz de confusi칩n y acierto

Para cada dendrograma obtenemos su matriz de confusi칩n y el porcentaje de acierto.

#### Dendrograma 칰nico

```{r}
wine_groups_unico <- cutree(wine_dend_unico, k = which.min(resultados_unico))
table(Type,wine_groups_unico)
```

```{r}
mc_unico <- table(Type, wine_groups_unico)
metricas(mc_unico)
```

```{r}
1 - metricas(mc_unico)[4]
```

#### Dendrograma medio

```{r}
wine_groups_medio <- cutree(wine_dend_medio, k = which.min(resultados_medio))
table(Type,wine_groups_medio)
```

```{r}
mc_medio <- table(Type, wine_groups_medio)
metricas(mc_medio)
```

```{r}
1 - metricas(mc_medio)[4]
```

#### Dendrograma completo

```{r}
wine_groups_completo <- cutree(wine_dend_completo, k = which.min(resultados_completo))
table(Type,wine_groups_completo)
```

```{r}
mc_completo <- table(Type, wine_groups_completo)
metricas(mc_completo)
```

```{r}
1 - metricas(mc_completo)[4]
```

### Comparando resultados

```{r}
acierto_unico <- 1 - metricas(mc_unico)[4]
acierto_medio <- 1 - metricas(mc_medio)[4]
acierto_completo <- 1 - metricas(mc_completo)[4]
tabla_aciertos <- data.frame(
  Metodo = c("Enlace 칰nico", "Enlace medio", "Enlace completo"),
  Acierto = c(round(acierto_unico * 100, 2), round(acierto_medio * 100, 2), round(acierto_completo * 100, 2))
)

tabla_aciertos
```

Al obtener el porcentaje de acierto de cada dendrograma podemos comparar estos resultados. Vemos el comportamiento de cada uno en relaci칩n al acierto a la hora de clasificar las variedades de vino. Teniendo en cuenta que los dendrogramas de *enlace 칰nico* y *completo* tienen un acierto bajo y muy cercano al otro, `32.58%` y `34.83%`, podemos decir que no son buenos para clasificar las 3 variedades de vinos, ya el de *enlace medio* presenta el mejor acierto con `65.17%`,

## e) Compara los resultados obtenidos por los distintos dendogramas y el obtenido por el algoritmo de K medias (洧 = 3) que mejor comportamiento ha ofrecido. 쮺u치l permite diferenciar mejor las tres variedades de vino?
