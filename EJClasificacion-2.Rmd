---
title: 'Ejercicio Clasificaci칩n: Regresi칩n Log칤stica, An치lisis discriminante lineal,
  cuadr치tico y KNN'
author: "Lu칤s Filipe Milhomem da Silva Paix칚o y Marcos Folguera Rivera"
date: "2023-04-14"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: true
    smooth_scroll: true
    theme: journal
    highlight: kate
    df_print: paged
    code_folding: show
---

# Base de datos

El conjunto de datos **Auto** usado en el an치lisis que est치 contenido en el paquete **ISLR**. Contiene el resultado de observar 洧녷 = 9 variables sobre 洧녵 = 392 veh칤culos.

```{r}
library(ISLR)
data(Auto)
attach(Auto)
Auto
```

```{r warning=FALSE}
library("vcd")
set.seed(1);
metricas<-function(mc){ #mc es una matriz de confusi칩n
  esp<-mc[1,1]/sum(mc[,1])
  sen<-mc[2,2]/sum(mc[,2])
  ag<-sum(diag(mc))/sum(mc)
  eg<-1-ag
  m<-cbind(esp,sen,ag,eg)
  colnames(m)=c("Especificidad","Sensibilidad","Exactitud","Error global")
  rownames(m)="valor"
  m
}
```

# 1. Calcula la mediana de la variable mpg. Crea una nueva variable mpg01 que tome el valor 1 si el dato de mpg correspondiente est치 por encima de dicha mediana, y 0 si es menor o igual que ese valor. Crea una nueva tabla de datos para incluir la nueva variable, que adem치s excluya el nombre del veh칤culo y la antigua variable mpg.

## Calculo de la mediana de mpg

**Calculamos la mediana** de la variable *mpg*. La variable *mpg* es el consumo de cada coche, en millas recorridas por gal칩n de combustible.

```{r}
mediana_mpg <- median(mpg)
```

**Creamos la variable mpg01**, tomando el valor 1 para cuando el dato (mpg) sea mayor que la mediana de la variable mpg calculada anteriormente y 0 en caso contrario.

```{r}
mpg01 <- ifelse(mpg <= mediana_mpg,1,0)
mpg01
```

## Creaci칩n de la nueva tabla (Auto2)

Ahora **creamos una nueva tabla**. Esta tabla estar치 basada en la de *Auto* incluyendo la nueva variable (mpg01), creada anteriormente, y excluyendo el nombre del veh칤culo y la variable mpg.

```{r warning=FALSE}
set.seed(1);
Auto2<-data.frame(cbind(Auto[-c(1,9)],mpg01))
Auto2
```

# 2. Crea un modelo de regresi칩n log칤stica para predecir mpg01 en funci칩n del resto de variables de Auto2. Indica cu치les son las 4 variables que est치n m치s fuertemente asociadas con mpg01.

## Regresi칩n Log칤stica

**Creamos un modelo de regresi칩n log칤stica** con la funci칩n *glm().* Dicho modelo busca predicir mpg01 en funci칩n del resto de variables de Auto2.

```{r}
modelo.logit <- glm(mpg01 ~ ., data=Auto2,family=binomial)
summary(modelo.logit)
```

```{r warning=FALSE}
library(vcd)
fp <- function(x) {
  variables<-0
  constante<-summary(modelo.logit)$coef[,"Estimate"][1]
  for(i in 2:length(summary(modelo.logit)$coef[,"Estimate"])) {
    variables<-summary(modelo.logit)$coef[,"Estimate"][i]*x
  }
  exp(constante+variables)/(1+exp(constante+variables))
}
summary(Auto2[1:7])
```

Calculamos la matriz/tabla de confusi칩n.

```{r}
# Hacer predicciones con el modelo
predicciones <- predict(modelo.logit, type="response") > 0.5
predicciones <- ifelse(predicciones == TRUE, 1,0)

# Crear la tabla de contingencia
matriz.rl <- table(Auto2$mpg01, predicciones, dnn=c("predicciones",
"observaciones"))

#Tabla de confusi칩n
matriz.rl
```

Con la funci칩n `metricas()`obtenemos la proporci칩n de error de este m칠todo, como otros resultados:

```{r}
metricas(matriz.rl)
```

Podemos graficar el resultado de matriz/tabla de confusi칩n con la funci칩n `mosaic()`:

```{r}
mosaic(matriz.rl,shade=T,colorize=T,
gp=gpar(fill=matrix(c("green","red","red","green"),2,2)))
```

## 4 variables que est치n m치s fuertemente asociadas con mpg01

Usamos los valores de los coeficientes estandarizados (z-values) de cada variable que nos proporciona el modelo de regresi칩n log칤stica para indicar las 4 variables que est치n fuertemente asociadas a mpg01.

Los coeficientes estandarizados (z-values) son una forma de comparar la fuerza de la asociaci칩n entre las variables independientes y la variable dependiente en un modelo estad칤stico. Cuanto mayor sea el valor absoluto del coeficiente estandarizado o z-value de una variable en un modelo de regresi칩n log칤stica, mayor ser치 la fuerza de la asociaci칩n entre esa variable y la variable dependiente.

```{r}
set.seed(1)
coeficientes_z <- summary(modelo.logit)$coef[, "z value"]
coeficientes_z_ordenados <- sort(coeficientes_z, decreasing = TRUE)
coeficientes_z_ordenados
```

As칤 podemos indicar las **4 variables que est치n fuertemente asociadas** a mpg01:

```{r}
nombres_variables <- row.names(summary(modelo.logit)$coef)
variables_fuertemente_asociadas <- nombres_variables[which(coeficientes_z %in% coeficientes_z_ordenados[1:5])]

variables_fuertemente_asociadas
```

# 3. Utiliza las 4 variables del apartado anterior para hacer an치lisis discriminante lineal. Calcula la matriz de confusi칩n y la proporci칩n de error que obtiene el m칠todo. Compara estos resultados con los del apartado anterior.

## An치lisis discriminante lineal

Hacemos el an치lisis discriminante lineal usando las 4 variables que est치n fuertemente asociadas a mpg01 con la funci칩n qda():

```{r warning=FALSE}
library(MASS)
set.seed(1);
modelo.qda <- qda(mpg01 ~ cylinders+horsepower+weight+acceleration, data=Auto2, CV=TRUE)
head(modelo.qda$class)
```

```{r}
head(modelo.qda$posterior)
```

Calculamos la matriz/tabla de confusi칩n.

```{r}
prediccion.qda<-modelo.qda$class
matriz.qda<-table(Predichos=prediccion.qda,Verdaderos=mpg01)
matriz.qda
```

Con la funci칩n `metricas()`obtenemos la proporci칩n de error de este m칠todo, como otros resultados:

```{r}
m_qda <- metricas(matriz.qda)
m_qda
```

Podemos graficar el resultado de matriz/tabla de confusi칩n con la funci칩n `mosaic()`:

```{r}
mosaic(matriz.qda,shade=T,colorize=T,gp=gpar(fill=matrix(c("green","red","red","green"),2,2)))
```

## Comparaci칩n de este m칠todo con el anterior

Dado que este m칠todo, an치lisis discriminante lineal, tiene un `Error global = 0.09693878` y el del m칠todo anterior, regresi칩n log칤stica, tiene un `Error global = 0.09183673`. As칤 que, el m칠todo de regresi칩n log칤stica obtiene mejores resultados.

# 4. Utiliza las 4 variables del apartado 2 para hacer an치lisis discriminante cuadr치tico. Calcula la matriz de confusi칩n y la proporci칩n de error que obtiene el m칠todo. Compara los resultados obtenidos por este m칠todo con los obtenidos para los dos m칠todos anteriores.

## An치lisis discriminante cuadr치tico

```{r}
library(MASS)
set.seed(1);
modelo.qda <- qda(mpg01 ~ cylinders+horsepower+weight+acceleration, data = Auto2,CV=T)
head(modelo.qda$class)
```

```{r}
prediccion<-modelo.qda$class
matriz.cuad<-table(Predichos=prediccion,Verdaderos=mpg01)

matriz.cuad
```

```{r}
metricas(matriz.cuad)
```

```{r}
mosaic(matriz.cuad,shade=T,colorize=T,gp=gpar(fill=matrix(c("green","red","red","green"),2,2)))
```

Podemos concluir que sale los mismos resultados que con an치lisis discriminante lineal por lo que las variables tienen la misma matriz de covarianza en todos los grupos.

## 5. Separa los datos seleccionando al azar 70 coches para predecir el grupo al que pertenecen y los 322 restantes como muestra de entrenamiento. Usa el m칠todo de los K vecinos m치s cercanos, con varios valores diferentes de K, para predecir mpg01 a partir de las 4 variables de los apartados anteriores. 쯈u칠 proporciones de error se obtienen? 쯈u칠 valor de K parece adecuado para este conjunto de datos? En general, 쯤u칠 modelo escoger칤as para predecir mpg01?

## KNN Vecinos m치s cercanos

Seleccionamos al azar 70 coches para predecir y el restando como muestro de entranamiento.

```{r}
set.seed(1);
clasificador<-mpg01
indices <- sample(1:nrow(Auto2), 70)

#Conjuntos de validacion y entrenamiento
validacion<-Auto2[indices,]
entrenamiento<-Auto2[-indices,]
predictors <- c("cylinders", "horsepower", "weight", "acceleration")
```

Se entrena con **varios valores para K.**

```{r}
library(class)
kmax=15
errork <- c()
for(i in 1:kmax){
  x<-knn(train=entrenamiento[, predictors],test=validacion[, predictors],cl=clasificador[-indices],k=i)
errork[i]<-metricas(table(Predichos=x,Verdaderos=clasificador[indices]))[4]

}
errork
```

Se **proporciona errores** muy cercanos unos a otros.

Gracias a la seguiente gr치fica podemos apreciar que con `K=3` da un **resultado 칩ptimo**.

```{r}
plot(c(1:kmax),errork,type="l")

```

Los resultados obtenidos:

```{r}
x<-knn(train=entrenamiento[, predictors],test=validacion[, predictors],cl=entrenamiento$mpg01,k=3)
matrizKNN<-table(x, validacion$mpg01)
metricas(matrizKNN)
```

# Conclusi칩n 

El peor metodo para realizar la predicci칩n es el de K-NN vecinos mas cercanos, aunque optimicemos el n칰mero de vecinos. El segundo peor metodo es an치lisis discriminante lineal ya que da los mismos resultados que an치lisis discriminante lineal y es mas complejo. Por lo cual regresi칩n log칤stica es el mejor m칠todo para predecir la variable mpg01 usando las variables m치s significativas del conjunto de datos :"*cylinders*", "*displacement*", "*year*", "*origin*". Aunque da mejores resultados comparandolo con todas las variables.

```{r}
library(dplyr)

qda_metricas <- metricas(matriz.qda)[4]
rl_metricas <- metricas(matriz.rl)[4]
knn_metricas <- metricas(matrizKNN)[4]
cuad_metricas <- metricas(matriz.cuad)[4]

tabla_metricas <- data.frame(M칠tricas = c("Discriminante Lineal", "Regresi칩n Log칤stica", "Discriminante Cuadr치tico", "KNN V. Cercanos"),
                             Valor_Error = c(qda_metricas, rl_metricas,cuad_metricas, knn_metricas))

tabla_metricas_ <- tabla_metricas %>% arrange(desc(Valor_Error))
tabla_metricas_
```
